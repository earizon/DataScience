● Pandas Cheat Sheet:
@[https://opensource.com/sites/default/files/uploads/pandas_cheat_sheet_github.png]

● Numpy cheatsheet:
https://cdn-images-1.medium.com/max/1000/1*qvSMwAWOd4cfett-57FUHA.jpeg

● Super cheat-sheet ML pdf:
@[./BecomingHumanCheatSheets.pdf]

● CITRIS (Center for Information Technology Research in the Interest of [[{101,data.mining,01_PM.TODO]]
  Society) está subiendo a su canal de Youtube los vídeos de las
  clases de un curso de minería de datos impartidos por el profesor
  Ram Akella en la Universidad de Berkeley.
@[https://www.datanalytics.com/2011/05/17/un-curso-completo-de-mineria-de-datos-en-youtube/
  Están disponibles los vídeos:
  - 26 de enero, sobre la regresión lineal
  -  2 de febrero, sobre la regresión logística
  -  9 de febrero, continuación del anterior
  - 16 de febrero, sobre métodos de clasificación (NN y naive bayes)
  - 23 de febrero, sobre naive bayes
     2 de marzo
  -  9 de marzo  , sobre diversas aplicaciones de SVD a problemas de minería de texto y motores de búsqueda
  - 16 de marzo  , sobre métodos de arracimamiento con aplicaciones a segmentación de mercados
  - 30 de marzo  , sobre extracción de la información
  - 13 de abril  , 20 de abril (día en el que todos llegaron tarde) y 27 de abril sobre motores de recomendación
  -  4 de mayo   , curiosamente al final, sobre aspectos más formales y globales de la minería de datos
[[}]]

● Probability vs Statistics
  https://towardsdatascience.com/probability-vs-statistics-95f221cc74f7

● L1/L2 regularization:
  The Elements of statistical Learning, Trevor Hastie, Robert
  Tibshirani and Jerome Friedman, Springer Science+Business Media, 2009

● Stacking algorithm: [[{ml,101,01_PM.TODO]]
- Stacking is an ensemble learning technique to combine multiple
  classification models via a meta-classifier. The individual
  classification models are trained based on the complete training set;
  then, the meta-classifier is fitted based on the outputs
  (meta-features) of the individual classification models in the
  ensemble. The meta-classifier can either be trained on the predicted
  class labels or probabilities from the ensemble.
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/
http://rasbt.github.io/mlxtend/user_guide/classifier/StackingCVClassifier/
[[}]]

● Python 4 Science:
  @[https://www.talyarkoni.org/blog/2013/11/18/the-homogenization-of-scientific-computing-or-why-python-is-steadily-eating-other-languages-lunch/]
- NumPy/SciPy: for numerical computing
- Neurosynth, NiPy etc.: for neuroimaging data analysis
- NumPy/SciPy/pandas/statsmodels: for statistical analysis
- MatPlotLib: for plotting and visualization, except for web-based visualizations (JavaScript/d3.js);
- scikit-learn: machine learning;
                breadth of implemented algorithms
                excellent documentation
                outstanding performance
- NLTK: Natural Language Processing
- BeautifulSoup: document parsing
 Visualization:
- <a href="http://www.datacommunitydc.org/blog/2013/05/stepping-up-to-big-data-with-r-and-python/">Stepping up to Big Data with R and Python: A Mind Map of All the Packages You Will Ever Need</a>

ReF: https://www.xmind.net/m/WvfC/
+-- Basic Stack
    +-- scikits image
    +-- scikits learn
    +-- scikits statsmodels
    +-- nltk
    +-- matplotlib

+-- Newer packages                         |+-- Packages
    +-- Numba                              |    +-- PyPI
    +-- wiseRF                             |+-- Efficiency
    +-- Blaze                              |    +-- Cython
                                           |+-- Paraller
+-- Integrated Platforms                   |    +-- iPython -- ipcluster
    +-- Continuum.io                       |    +-- PP
        +-- Anaconda                       |    +-- dispy
        +-- Wakari                         |+-- GPU
    +-- PiCloud  --- Python + AWS          |    +-- NumbaPro
    +-- wise.io  -- MLaaS  -- RandomForest |    +-- PyCUDA
    +-- ipython -- Notebook                |+-- Glue
    +-- Orange                             |    +-- rpy2 -- R
                                           |    +-- PySpark -- Spark
+-- Visualization                          |    +-- ipython -- "magic"
    +-- matplotlib                         |                   +-- R
    +-- Bokeh  -- ggplot for python        |                   +-- SQL
    +-- Mayavi                             |                   +-- matlab/octave
    +-- Nodebox                            |                   +-- IDL
    +-- igraph                             |   +-- jython -- java
    +-- pandas  -- pandas.tools.rplot      |     +-- boto   -- Amazon Web Services
    +-- Google APIs  -- goggleVis

+-- Data formats                | +-- MapReduce
    +-- Flat text               |     +-- Hadoop Interface
        +-- xreadlines          |         +-- Hadoop Streaming
        +-- readlines           |             +-- Hadoopy
        +-- pandas              |             +-- dumbo
            +-- read_csv        |             +-- mrjob
            +-- read_fwf        |
        +-- xlrd/xlwt/xlutils   |         +-- Pydoop -- Pipes
    +-- HDF5                    |     +-- disco
        +-- PyTables
        +-- h5py
    +-- SQL
        +-- SQLAlchemy
        +-- pysqlite3
        +-- pyodbc
            +-- Vertica
            +-- Netezza
            +-- Teradata
    +-- NoSQL
        +-- MongoDB - PyMongo
        +-- CouchDB
            +-- couchdb-python
            +-- couchdbkit
    +-- JSON
        +-- Standard Library
        +-- simplejson
    +-- XML
        +-- Standard Library
    +-- HBase
        +-- HappyBase

Web scraping:
    Scrapy:

● Best Python modules for data mining
@[https://www.kdnuggets.com/2012/11/best-python-modules-for-data-mining.html]

Basics:
    numpy - numerical library, numpy.scipy.org/
    scipy - Advanced math, signal processing, optimization, statistics, www.scipy.org/
    matplotlib, python plotting - Matplotlib, matplotlib.org

Machine Learning and Data Mining:
    MDP, a collection of supervised and unsupervised learning algorithms, pypi.python.org/pypi/MDP/2.4
    mlpy, Machine Learning Python, mlpy.sourceforge.net
    NetworkX, for graph analysis, networkx.lanl.gov/
    Orange, Data Mining Fruitful & Fun, biolab.si Pandas
    pandas, Python Data Analysis Library, pandas.pydata.org
    pybrain, pybrain.org
    scikits-learn - Classic machine learning algorithms - Provide
       simple an efficient solutions to learning problems,
       scikit-learn.org/stable/

Natural Language:
    NLTK, Natural Language Toolkit, nltk.org

For web scraping:
    Scrapy, An open source web scraping framework for Python scrapy.org
    urllib/urllib2



● Excellent Graphical Summary to Data Science
https://www.linkedin.com/feed/update/urn:li:activity:6614480425756782592/

● NumPy@StackOverflow:
@[https://stackoverflow.com/questions/tagged/numpy?tab=Votes]

● External Links:
  Forcibly incomplete but still quite pertinent list of interesting Machine Learning Links
  - @[https://pydata.org/]
  - @[https://www.reddit.com/r/MachineLearning/]
  - @[https://www.datasciencecentral.com/]
    Industry's online resource for data practitioners.
    From Statistics to Analytics to Machine Learning to AI,

  - @[https://towardsdatascience.com/]

  - @[https://course.elementsofai.com/]

  - https://opendata.stackexchange.com/tags     Open Data Taxonomy
  - https://datascience.stackexchange.com/tags  Data Science Taxonomy

  - @[http://arxiv.aiindex.org/]
    ArXiv Monitor is a full paper search engine tool with the goal to automatically
    and continuously track technical metrics from papers published on arXiv. AI
    Progress monitor is intended to provides a high-level overview of AI progress
    across task, dataset, category, technical metrics and other relevant categories.

  - @[https://ai.googleblog.com/]
    Latest news from Google AI.

  - @[https://ai.google/tools/#developers]
  - Classification:
    - @[https://www.w3.org/wiki/Lists_of_ontologies]
    - Ontology (Aristoteles):
      @[http://classics.mit.edu/Aristotle/categories.1.1.html]

    - Main classification of search types in Google according to Google Trends:
      - arts and entretainement  - hobbies+and+leasure   - Reference
      - autos vehicles           - home+and+garden       - Science
      - beauty and fitness       - Internet+and+telecoms - shopping
      - books+and+literature     - Jobs+and+education    - Sport
      - business+and+industrial  - law+and+governement   - Travel
      - Computer+and+electronics - news
      - Finance                  - online comunities
      - food+and+drink           - people+and+society
      - games                    - pets+and+animals
      - health                   - Real State

  - @[https://docs.python.org/3.6/library/statistics.html]
    Basic statistics module included in Python 3.4+.
    NumPy/SciPy is prefered for advanced use-cases.
    Includes functions for:
    - averages⅋"middles":
      Arithmetic|Harmonic mean, (Low|High)Median , Mode/most-common-value
    - Measures of spread:
      (population|)standard deviation, (population|) variance

  - Fundations Video Tutorials by Brandon Rohrer
    @[https://www.youtube.com/user/BrandonRohrer]

● BIBLIOGRAPHY:
  - Probability:
    Statistics, third edition, by Freedman, Pisani, and Purves,
    published by W.W. Norton, 1997.
  - The Lack of A Priori Distinctions Between Learing Algorithms, D.H.Wolpert (1996); [101]
    No free lunch theorems for optimization, D.H. Wolpert y W.G.Macready (1997)

  - McCullock-Pitts  (MCP), A Logical Calculus of the Ideas Immanet in Nervous Activity,
    W.S. McCulloch  and W.Pitts, Bulletin of Mathematical Biophysics, 5(4): 115-133, 1943

  - An algorithm for finding best matches in logarithmic Expected Time,  101
    J.H.Friedman, J.L,  Bentley, and R.A. Finkel, ACM transactions on
    mathematical software (TOMS), 3(3): 209-226, 1977

  - https://github.com/rasbt/python-machine-learning-book-2nd-edition

  - https://1lib.eu/book/4989630/29a81f?dsource=mostpopular
  - https://1lib.eu/book/3717886/b95236?dsource=mostpopular
  - https://1lib.eu/book/3698789/ad21bb
  - https://1lib.eu/book/5668172/a7be15

● iterative/dvc: 🦉Data Version Control | Git for Data & Models     [[{01_PM.low_code]]
  https://github.com/iterative/dvc 
[[}]]

● ML explotation: Predictive Model Markup Language - Wikipedia
  https://en.m.wikipedia.org/wiki/Predictive_Model_Markup_Language 
  https://github.com/AmadeusITGroup/H2O-to-PMML

● Internal Machine-Learning Courses Public                        [[{cloud}]]
https://www.infoq.com/news/2020/08/amazon-machine-learning-courses/

● GPT-3 https://planaspa.com/2020/07/26/GPT-3.html

● Feature Importance Is All You Need | Kaggle
  https://www.kaggle.com/louise2001/rapids-feature-importance-is-all-you-need
   RAPIDS is a suite of packages developed out of NVIDIA, that intends
  to execute end-to-end data science and analytics pipelines entirely
  on GPUs. The goal of this notebook is to perform univariate
  regressions of each target on every feature, namely 872 x 206 =
  179632 logistic models to estimate separately. The good news ? This
  is possible within minutes with RAPIDS !


● Diagram of universal machine learning
  https://www.linkedin.com/posts/marco-tavora_machinelearning-activity-6684717542117847040-iaxM
● Cheatsheet IA scikit / RLang
  https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/

● Salesforce Releases Photon Natural Language Interface for Databases
  https://www.infoq.com/news/2020/09/salesforce-natural-language/
● Diffbot's Natural Language API
  https://www.diffbot.com/products/natural-language/


● octosql: query tool that allows you to join, analyse and transform data  [[01_PM.low_code]]
           from multiple sources
  https://github.com/cube2222/octosql
 ... streaming sources and file formats using SQL.Problems OctoSQL
  SolvesYou need to join / analyze data from multiple datasources.Think
  of enriching an Excel file by joining it with a PostgreSQL
  database.You need stream aggregates over time, with live output
  updates.Think of a live-updated leaderboard with cat images based on
  a "like" event stream.You need aggregate streams per time window,
  with live output updates.Think of a unique user count per hour, per
  country live summary.
  https://github.com/cube2222/octosql/releases/tag/v0.3.0
● Hardware Acceleration for Big Data Analytics:
  How Enterprises Can Achieve Better Performance?
 https://medium.com/ntt-disruption/hardware-acceleration-for-big-data-analytics-how-enterprises-can-achieve-better-performance-d473ca721f28

● Databrick Mlflow
  https://www.infoq.com/news/2020/07/mlflow-linux-foundation/
● voila-dashboards/voila: Voilà turns Jupyter notebooks into
  standalone web applications https://github.com/voila-dashboards/voila 

● Tensorflow on edge, or – Building a "smart" security camera with a Raspberry Pi   [IoT]
  https://chollinger.com/blog/2019/12/tensorflow-on-edge-or-building-a-smart-security-camera-with-a-raspberry-pi/

  Object Detection in RPi:
  https://github.com/EdjeElectronics/TensorFlow-Object-Detection-on-the-Raspberry-Pi
  A tutorial showing how to set up TensorFlow's Object Detection API on the Raspberry Pi

● What's new spark 3
  https://www.infoq.com/news/2020/07/spark-ai-summit-performance-gpu/

● TimeSeries data analysis      01_PM.low_code:
  https://www.influxdata.com/

● https://blog.scottlogic.com/2020/01/03/webassembly-sudoku-solver.html
  Real time sudoku solver from webcam image using WebAssembly, OpenCV
  and TensorFlow.js.
  OpenCV is used to clean data before being injected to Tensorflow
  for number recognition and localization into 2D.
  Finally Rust/WebAssemble solves the puzzle.

● Low code ML tools:  [[01_PM.low_code]]
  https://www.managedfunctions.com/pirate/managedfunctions/

● https://ignite.apache.org/features/machinelearning.html

● TensorFlow.js: Teaching Computer to Play Dinosaurs
  https://www.infoq.com/news/2019/04/tensorflow-chrome-dinosaur-game/
● [Video] Scale deep learning to petaflops   [[scalability]]
  https://www.infoq.com/presentations/scale-dl-petaflops/
  Prabhat explores 2D and 3D convolutional architectures for solving
  pattern classification, regression and segmentation problems in
  high-energy physics, cosmology and climate science.


● Better Language Models and Their Implications</span>
@[https://openai.com/blog/better-language-models/]
  We’ve trained a large-scale unsupervised language model which
  generates coherent paragraphs of text, achieves state-of-the-art
  performance on many language modeling benchmarks, and performs
  rudimentary reading comprehension, machine translation, question
  answering, and summarization—all without task-specific training.

● https://m.europapress.es/ciencia/laboratorio/noticia-algoritmos-son-capaces-descubrir-conocimiento-cientifico-oculto-20190704110622.html
● https://www.infoq.com/news/2019/07/google-dlc-beta-release/ [[{cloud,devops}]]
  Google Releases Deep Learning Containers into Beta
● data Science Taxonomy:
@[https://datascience.stackexchange.com/tags]
@[https://opendata.stackexchange.com/tags]
● https://www.infoq.com/news/2019/05/google-ai-platform/
  Google has recently launched AI Platform, an end-to-end platform for
  developers and data scientists to build, test, and deploy machine
  learning models

● 100$ camera, 50%+ "NewYorkers" detected:
  https://www.nytimes.com/interactive/2019/04/16/opinion/facial-recognition-new-york-city.html
  Related [ES]:
  http://www.redusers.com/noticias/investigadores-belgas-descubren-metodo-enganar-camaras-ia/

● https://ml-cheatsheet.readthedocs.io

● Detailed evaluations of different secuencials algorithms  can be found on:
  Comparative Study of Techniques for Large-Scale Feature Selection,
  F.Ferri, P. Pudil, M. Hatef and J. Kittler, pages 403-413, 1994

● A Study of Cross-Validation and Bootstrap for Accuracy Estimation and
  Model Selection, Kohavi, Ron, International Joint
  Conference on Artificial Intelligence (IJCAI), 14(12): 1137-43, 1995

● https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html
  https://sebastianraschka.com/blog/2016/model-evaluation-selection-part2.html
  https://sebastianraschka.com/blog/2016/model-evaluation-selection-part3.html

● Analysis of Variance of Cross-Validation Estimators of the
  Generalization Error, M.Markatou, H.Tian, S.Biswas, and G.M.
  Hripcsak, Journal of Machine Learning Research, 6: 1127-1168, 2005

● Improvements on Cross-validation: The .632+ Bootstrap Method, B.
  Efron and R. Tibshirani, Journal of the American Statistical
  Association, 92 (438): 548-560, 1997

● Model evaluation and hyper-params
  Error Estimation When Using Cross-validation for Model Selection,
  BMC Bioinformatics, S. Varna and R. Simon, 7(1):91, 2006

● https://www.infoq.com/news/2019/11/alexa-genetic-deep-learning/
  https://arxiv.org/abs/1908.09942
  Amazon's Alexa Science researchers published a paper providing a
  theoretical basis for neural-network optimization. While showing that
  it is computationally intractable to find a perfect solution, the
  paper does provide a formulation, the Approximate Architecture Search
  Problem (a-ASP), that can be solved with genetic algorithms.

● kubeflow:
  https://www.kubeflow.org/
  The Machine Learning Toolkit for Kubernetes

● https://root.cern/primer/: analyzing petabytes of data, scientifically. [[scalability]]
  ROOT enables statistically sound scientific analyses and
  visualization of large amounts of data: today, more than 1 exabyte
  (1,000,000,000 gigabyte) are stored in ROOT files. The Higgs was
  found with ROOT!

  ROOT comes with an incredible C++ interpreter, ideal for fast
  prototyping. Don’t like C++? ROOT integrates super-smoothly with
  Python thanks to its unique dynamic and powerful Python ⇄ C++
  binding. Or what about using ROOT in a Jupyter notebook?

  https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/

● Spark "bullet points":
  https://dzone.com/articles/the-magic-of-apache-spark-in-java-1?edition=671395

● Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs
  https://medium.com/syncedreview/google-replaces-bert-self-attention-with-fourier-transform-92-accuracy-7-times-faster-on-gpus-7a78e3e4ac0e

● CPU faster than GPU scenarios(search/Hash tables) [[{02_doc_has.comparative,scalability]]
https://techdecoded.intel.io/resources/the-role-and-potential-of-cpus-in-deep-learning/
   CPUs are more suitable for such applications with limited
  parallelism because of their advanced memory management techniques.
  For example, researchers from Rice University have shown that for
  fully connected networks over sparse datasets such as Amazon-670K,
  and Delicious-200K, the DL training problem can be modeled as a
  search problem:
  This allows replacing matrix multiplication operation with
  hash tables  allowing CPU to provide higher performance than
  a TensorFlow-based implementation on GPU.
[[}]]

● Towards Data Science: Marcleo Rovai:
  https://towardsdatascience.com/@rovai

● https://github.com/Jaewan-Yun/optimizer-visualization
  Visualize gradient descent optimization algorithms in Tensorflow.

● MIT Researchers Open-Source Approximate Matrix Multiplication Algorithm MADDNESS [[{scalability]]
  https://www.infoq.com/news/2021/10/mit-matrix-multiplication/ 
  Matrix multiplication is a fundamental operation in machine
  learning, and is one of the most time-consuming, due to the extensive
  use of multiply-add instructions. Because GPU and TPU chips can
  execute many multiply-adds in parallel, they perform matrix
  multiplication faster than CPUs, making them attractive for ML
  applications; however, they may be too expensive or even unavailable
  for researchers with a limited budget, or in resource-constrained
  applications like IoT. Thus, many researchers have investigated AMM
  algorithms, which trade off accuracy of matrix multiplication for
  speed.

    The team described MADDNESS and a set of experiments in a paper
  presented at the recent International Conference on Machine Learning
  (ICML). Unlike many other AMM algorithms, MADDNESS uses no
  multiply-add operations. Instead, MADDNESS uses a set of efficient
  learned hash functions that achieve coding rates of 100GB/second
  using only one CPU thread. The hash functions map input data to an
  index into a lookup table that contains pre-computed dot-products.
  Although the algorithm does introduce some output error, the authors
  show the algorithm has a theoretical upper-bound on the error, which
  can be traded-off against speed. In a set of experiments comparing
  the performance of MADDNESS against other algorithms in an image
  classifier, the researchers found that MADDNESS has a better
  speed-accuracy tradeoff, and achieves "virtually the same accuracy as
  exact multiplication" while being 10x faster.
[[}]]

● https://blog.ephorie.de/why-r-for-data-science-and-not-python

● R vs python, by Keith McNulty
Expert Mathematician, Applied Statistician, Psychometrician, Data Scientist
   If you are new to programming and If your priority is deeply
  understanding statistical relationships, you may wish to start with
  #rstats. If your priority is running predictions of a phenomenon with
  a minimum amount of code you may wish to start with #python
  especially if you are already familiar with object-oriented
  principles. But if you are committed, over time eventually you’ll
  learn both because they are both very interesting and capable
  languages. #datascience #analytics #peopleanalytics #data Comment

Comments:
 William Ferreira
... R is a purpose designed environment for statistical modelling, inference and many other related things.
 R also happens to be a programming language, and Turing-complete, but not a general purpose one,
having been designed to work within the R framework; a bit like VBA being associated with Excel and other
MS applications.

Holger K. von Jouanne-Diedrich
I am a professor ... I don't agree. When you want to learn data science with Python you basically
have to learn two languages, with R only one because it was designed for that matter.
More here in my blog post: https://blog.ephorie.de/why-r-for-data-science-and-not-python

 Sergey Mastitsky Data Science Lead at Aviva
Especially with technologies like Docker, which allow Data Scientists to develop their applications in
pretty much any language they are comfortable with, and then pass on to engineers, who will know what
to do next.

Valeriy M.
Machine Learning | Data science | Systematic Trading | Forecasting Innovation | Industry 4.0 | Advanced Analytics | Time-series
  IF “UNDERSTAND THE PHENOMENON” MEANS FITTING PARAMETRIC MODEL THEN YES.
  IT IS CALLED STATISTICS, R IS CERTAINLY BETTER FOR STATISTICS BECAUSE IT WAS DEVELOPED BY STATISTICIANS FOR STATISTICIANS..
  BUT FUNDAMENTALLY IT IS NOT ABOUT WHICH LANGUAGE TO USE. IT IS ABOUT MAKING QUALITY PREDICTIONS.
  MACHINE LEARNING MOVED PAST PARAMETRIC MODELS AND IS USING DATA DRIVEN PREDICTIONS BECAUSE
  THE MAIN GOAL OF ANY MODEL IS NOT TO FIT A CONTRIVED PARAMETRIC MODEL TO THE DATASET,
  BUT TO PREDICT WELL OUT OF SAMPLE TO GENERATE VALUE.

   ALL PARAMETRIC MODELLING DOES IS GIVING FALSE SENSE OF "MASTERING THE DATA" BY FITTING GAUSSIAN AND
  OTHER CLASSICAL DISTRIBUTIONS TO DATA THAT, UNLESS BEING SYNTHETIC, NEVER FOLLOWS SUCH DISTRIBUTIONS.
   AND THE RESULT IS MODEL MISMATCH RESULTING IN INCORRECT AND BIASED PREDICTIONS.
    SO WOULD ONE REALLY PREFER TO "UNDERSTAND" THE DATA (AS IN FITTING PARAMETRIC MODEL)
  OR HAVE MUCH BETTER PREDICTIONS THAT GENERATE BUSINESS VALUE?
  DEPENDS ON PERSPECTIVE, “UNDERSTAND” WORKS WELL IN SCHOOL STATISTICS 1.01 CLASSES AND ACADEMIA,
  BUT IS NOT VERY USEFUL TO GENERATE BUSINESS VALUE VIA BETTER PREDICTIONS.

 Rami KrispinData Science Manager at Apple
I find this statement fundamentally wrong, I am doing both descriptive and predictive solely with R
(and deploy it on production). And definitely, nowadays, you can do both with Python.
There are some applications that may available in one but not on the other, and this a good motivation
for focusing on one out the two.

Adrian Olszewski
Principal Biostatistician at 2KMM CRO, Clinical Research with R
 My field is a good example. The community didn't care and overslept one of the most prestigious
and beneficial industries the Clinical Research (drug evaluation and approval),
)LETTING SAS AND R TO CONSTITUTE TWO DE FACTO INDUSTRY STANDARDS (SAS - the absolute majority, R - supportive yet,
 as it still lacks a few key features).
 Actually, a similar thing happens to R. SAS has all the stuff required by the industry,
so people choose it rather than bringing the stuff to R. Luckily, as R was present in Pharma for decades,
they started contributing a lot recently, yet a lot is still to be done.

Jason Cherry
...As time has gone on the divergence of analytical capabilities between the two languages has decreased.
I will say that ggplot is still way better than anything comparable dataviz-wise in Python,
but those cases are rarer and rarer.
For me, I chose Python because of the libraries that exist for it are more general-purpose.
 I can not only build a fully-functioning analytical solution in Python, but I can wrap it in
a REST API and spin that up more easily as a containerized solution that plays nice with other
functionality it may need to interact with.
 R has some functionality here too, but it's lagging behind enough that I really do prefer Python
in a setting where I'm working on something that could have a pipeline to production, and/or
I'm working with software engineers at some point of the project.

Alberto Almuiña
There are also some time series methods that are not implemented in Python, such as the
multiple seasonal decomposition from the forecast package and others.

Adrian Olszewski:
it's about numerous key tools I use every day at work... I maintain a list
(it's outdated, have to add new stuff soon):
https://www.quora.com/What-domain-specific-statistical-capabilities-exist-in-R-but-do-not-in-Python/answer/Adrian-Olszewski-1?ch=10&share=a32559e2&srid=MByz 2

Keith McNulty Expert Mathematician, Applied Statistician, Psychometrician, Data Scientist
In Python last time I looked you can NOT do proportional odds regression for the purposes
of inference in stats-models although they do have a version for predictive classification.
 And mixed GLMs don’t exist. Also major limitations on tests of significant coefficient
difference like the wald test. Also no packages for effect sizes.
  R is still working towards a mature consistent framework for predictive analytics.
The tidymodels ecosystem is making progress but it is not at the Python level yet.

● ML: Taxonomy https://juliastats.org/

● ML: La nueva y sorprendente IA de Facebook es capaz de transcribir de voz a texto sin haber sido entrenada
  con transcripciones
  https://www.xataka.com/robotica-e-ia/nueva-sorprendente-ia-facebook-capaz-transcribir-voz-a-texto-haber-sido-entrenada-transcripciones 

  Para ello, el sistema se vale de una GAN (red generativa
  antagónica) que, de acuerdo a Facebook, compite de tú a tú con los
  mejores sistemas supervisados de hace unos años.

______________________________
● Chatear con tu yo del pasado como opción de futuro:
  la inteligencia artificial y sistemas como GPT-3 lo hacen posible
  https://www.xataka.com/robotica-e-ia/chatear-tu-yo-pasado-como-opcion-futuro-inteligencia-artificial-sistemas-como-gpt-3-hacen-posible

● Crean el primer cerebro electrónico que aprende como el humano
  https://www.elconfidencial.com/amp/tecnologia/novaceno/2021-04-30/cerebro-neuronas-ciencia-computadoras_3059171/

● Microsoft Releases AI Training Library ZeRO-3 Offload
  https://www.infoq.com/news/2021/04/microsoft-zero3-offload/ 
  Microsoft recently open-sourced ZeRO-3 Offload, an extension of their
  DeepSpeed AI training library that improves memory efficiency while
  training very large deep-learning models. ZeRO-3 Offload allows users
  to train models with up to 40 billion parameters on a single GPU and
  over 2 trillion parameters on 512 GPUs.

● ML: amrrs/30-seconds-of-r-code: Collection of small base-R expressions (r snippets)
  https://github.com/amrrs/30-seconds-of-r-code

● Text2Code: A Jupyter extension to convert English text to python code
  https://www.marktechpost.com/2020/09/13/text2code-a-jupyter-extension-to-convert-english-text-to-python-code/

● DebugEverything
 https://blog.debugeverything.com/virtual-environments-with-python-virtualenv/

● http://pkpd.kmu.edu.tw/ 
  https://www.quora.com/What-domain-specific-statistical-capabilities-exist-in-R-but-do-not-in-Python/answer/Adrian-Olszewski-1?ch=10&share=a32559e2&srid=MByz

● ML: Software Development Lab. for Free PK/PD/Pharma R&D (drug stability, ivivc & BE/BA) Data Analytical Tools

● Booking.com released UpliftML, a new #python library for scalable
  unconstrained and constrained uplift modeling from experimental data.
  The library leverages PySpark and H2O models as the framework for uplift models.
  - Uplift modeling is a family of techniques for estimating the Conditional
  Average Treatment Effect (CATE) from experimental or observational
  data using machine learning. In particular, we are interested in
  estimating the causal effect of treatment T on the outcome Y of an
  individual characterized by features X. In experimental data with
  binary treatments and binary outcomes, this is equivalent to
  estimating Pr(Y=1 | T=1, X=x) - Pr(Y=1 | T=0, X=x).Thanks to the
  library contributors - Javier Albert and Irene Teinemaa, and to Noa
  Barbiro and Dima Goldenberg for sharing!
  𝐋𝐢𝐜𝐞𝐧𝐬𝐞: Apache 2 Documentation:
  https://lnkd.in/gPYUm3DZ Source Code:
  https://lnkd.in/ghGTMYZV
  Examples:
  https://lnkd.in/gdsQDyxB
  https://booking.ai/#machinelearning #causalinference #experimentation #ml #datascience #datascientist #h2o #pyspark

● [https://www.infoq.com/news/2021/09/tesla-dojo-ai-models/]

● MIT Demonstrates Energy-Efficient Optical Accelerator for Deep-Learning Inference
  https://www.infoq.com/news/2021/08/mit-optical-deep-learning/

● Anomaly detection: ML: Screenshot (29 sept. 2021 21:52:23)
  file:///tmp/mozilla_earizon0/Screenshot_20210929-215223.png

● Una inteligencia artificial refuta cinco conjeturas matemáticas sin ayuda humana
  https://www.lavanguardia.com/tecnologia/actualidad/20210525/7477912/inteligencia-artificial-refuta-conjeturas-matematicas-ayuda-humana.html

● https://www.kdnuggets.com/2021/05/data-scientist-data-engineer-data-careers-explained.html

● https://youtu.be/_8V5o2UHG0E
  dataset types: Tables, networks, spatial (fileds/continuos, geometry/position)


● Hasta AWS se pasa al low-code:
  Workflow Studio es su primera herramienta de desarrollo de bajo código
https://www.xataka.com/pro/aws-se-pasa-al-low-code-workflow-studio-su-primera-herramienta-desarrollo-codigo

● Bicameral Mind - Humanoid Robot With GPT-3 as the Story-Teller | by Suphi Evrakzade | The Startup | Medium
  https://medium.com/swlh/bicameral-mind-humanoid-robot-with-gpt-3-as-the-story-teller-dcd06d5c7f8d

● https://github.com/deepmind/deepmind-research
  This repository contains implementations and illustrative code to
  accompany DeepMind publications

● https://www.freemaptools.com/
  geo-data:
  An online resource that enables visitors to easily and quickly use
  maps in order to measure, search and overlay mark-up elements on maps
  for a wide range of useful applications. Click on one of the Map
  Tools below to find out more...


● https://bookdown.org/:
  Write HTML, PDF, ePub, and Kindle books with R Markdown
  OOSS R package that facilitates writing books and
  long-form articles/reports with R Markdown. Features include:
  - Generate printer-ready books and ebooks from R Markdown documents.
  - A markup language easier to learn than LaTeX, and to write elements
    such as section headers, lists, quotes, figures, tables, and
    citations.
  - Multiple choices of output formats: PDF, LaTeX, HTML, EPUB, and
    Word.
  - Possibility of including dynamic graphics and interactive
    applications (HTML widgets and Shiny apps).
  - Support a wide range of languages: R, C/C++, Python, Fortran,
    Julia, Shell scripts, and SQL, etc.
  - LaTeX equations, theorems, and proofs work for all output formats.
  - Can be published to GitHub, bookdown.org, and any web servers.
  - Integrated with the RStudio IDE.
  - One-click publishing to https://bookdown.org.

● ML: Shiny examples
  https://shinylive.io/py/examples/#reactive-calc

● https://media-exp1.licdn.com/dms/image/C5622AQHl_03AIXIH2A/feedshare-shrink_480/0/1658555003262?e=1661990400&v=beta&t=IHb6CXAmfVpviXA7NCKgMf7gQXo0s0OaAHXV_CybOqg

● PyTorch 1.10 Release Includes CUDA Graphs APIs, Compiler Improvements,
  and Android NNAPI Support
  https://www.infoq.com/news/2021/11/pytorch-release-cuda-android/

● DeepMind Releases Weather Forecasting AI Deep Generative Models of Rainfall
  https://www.infoq.com/news/2021/12/deepmind-weather-forecasting/ 

● Stan (Stats Inference):
  @[https://en.wikipedia.org/wiki/Stan_(software)]
  Stan is a probabilistic programming language for statistical
  inference written in C++.[1] The Stan language is used to specify a
  (Bayesian) statistical model with an imperative program calculating
  the log probability density function.[1]

  Named in honour of Stanislaw Ulam, pioneer of the Monte Carlo method.

  Stan was created by a development team consisting of 34 members
  that includes Andrew Gelman, Bob Carpenter, Matt Hoffman, and Daniel
  Lee.

  Interfaces

  Stan can be accessed through several interfaces:

      CmdStan    - command-line executable for the shell
      RStan      - integration with the R software environment, maintained
                   by Andrew Gelman and colleagues
      PyStan     - integration with the Python programming language
      MatlabStan - integration with the MATLAB numerical computing
                   environment
      Stan.jl    - integration with the Julia programming language
      StataStan  - integration with Stata

  @[https://mc-stan.org/]

  Stan is a state-of-the-art platform for statistical modeling and
  high-performance statistical computation.
  - Use cases:
    - statistical modeling
    - data analysis
    - prediction in social, biological, physical sciences, engineering, and business.

  Users specify log density functions in Stan's probabilistic programming language and get:
  - full Bayesian statistical inference with MCMC sampling (NUTS, HMC)
  - approximate Bayesian inference with variational inference (ADVI)
  - penalized maximum likelihood estimation with optimization (L-BFGS)
  - Stan's math library provides differentiable probability functions⅋linear algebra
    (C++ autodiff).
    - Additional R packages provide expression-based linear modeling,
      posterior visualization, and leave-one-out cross-validation.

● Pyro: Deep Universal Probabilistic Programming
  @[http://pyro.ai/]
  REF(ES): @[https://www.datanalytics.com/2019/10/14/pyro/]
  "Stan en Python y a escala...
  ... parece que su especialidad es la inferencia variacional estocástica.
  Que parece funcionar de la siguiente manera. En el MCMC tradicional
  uno obtiene una muestra de la distribución (a posteriori, para los amigos)
  de los parámetros de interés. Eso es todo: vectores de puntos.
  En la inferencia variacional estocástica, uno preespecifica la forma
  paramétrica de la posteriori y el algoritmo calcula sus parámetros
  a partir de los valores simulados. Por ejemplo, uno va y dice:
  me da que la distribución del término independiente de mi regresión lineal
  va a ser normal. Entonces, Pyro responde: si es normal, la mejor media
  y desviación estándar que encuentro son tal y cual.

  La segunda observación que me permito hacer es que la forma que adquiere la
  implementación de modelos en Pyro está muy alejada de la forma en que los
  plantearía un estadístico. Uno lee código en Stan o Jags y entiende lo
  que está ocurriendo: las servidumbres al lenguaje subyacente son mínimas y
  existe un DSL conciso que permite expresar los modelos de una manera natural.
  Pero no pasa así con Pyro. "

● SnakeMake: create reproducible and scalable data analyses  [[qa]]
@[https://snakemake.readthedocs.io/en/stable/]
The Snakemake workflow management system is a tool to create
reproducible and scalable data analyses. Workflows are described via
a human readable, Python based language. They can be seamlessly
scaled to server, cluster, grid and cloud environments, without the
need to modify the workflow definition. Finally, Snakemake workflows
can entail a description of required software, which will be
automatically deployed to any execution environment.

Snakemake is highly popular with, ~3 new citations per week.
Quick Example

Snakemake workflows are essentially Python scripts extended by
declarative code to define rules. Rules describe how to create output
files from input files.

rule targets:
    input:
        "plots/myplot.pdf"

rule transform:
    input:
        "raw/{dataset}.csv"
    output:
        "transformed/{dataset}.csv"
    singularity:
        "docker://somecontainer:v1.0"
    shell:
        "somecommand {input} {output}"

rule aggregate_and_plot:
    input:
        expand("transformed/{dataset}.csv", dataset=[1, 2])
    output:
        "plots/myplot.pdf"
    conda:
        "envs/matplotlib.yaml"
    script:
        "scripts/plot.py"

● Dask.org: [[devops,scalability]]
   Dask's schedulers scale to thousand-node clusters and its
 algorithms have been tested on some of the largest supercomputers in
 the world. But you don't need a massive cluster to get started. Dask
 ships with schedulers designed for use on personal machines.
     Dask is open source and freely available. It is developed in
 coordination with other community projects like Numpy, Pandas, and
 Scikit-Learn.

● Luigi [[devops]]
  Python (2.7, 3.6, 3.7 tested) package that helps you
  build complex pipelines of batch jobs. It handles dependency
  resolution, workflow management, visualization, handling failures,
  command line integration, and much more.

  There are other software packages that focus on lower level aspects
  of data processing, like Hive, Pig, or Cascading. Luigi is not a
  framework to replace these. Instead it helps you stitch many tasks
  together, where each task can be a Hive query, a Hadoop job in Java,
  a Spark job in Scala or Python, a Python snippet, dumping a table
  from a database, or anything else. It’s easy to build up
  long-running pipelines that comprise thousands of tasks and take days
  or weeks to complete. Luigi takes care of a lot of the workflow
  management so that you can focus on the tasks themselves and their
  dependencies.

● DENSE (DeepLearning for Science)
https://www.infoq.com/news/2020/03/deep-learning-simulation/
https://arxiv.org/abs/2001.08055
researchers from several physics and geology laboratories have developed Deep
Emulator Network SEarch (DENSE), a technique for using deep-learning to perform
scientific simulations from various fields, from high-energy physics to climate
science. Compared to previous simulators, the results from DENSE achieved
speedups ranging from 10 million to 2 billion times.

The scientists described their technique and several experiments in a paper
published on arXiv. Motivated by a need to efficiently generate neural network
emulators to replace slower simulations, the team developed a neural search
method and a novel super-architecture that generates convolutional neural
networks (CNNs); CNNs were chosen because they perform well on a large set of
"natural" signals that are the domain of many scientific models. Standard
simulator programs were used to generate training and test data for the CNNs,
and according to the team,

● Singa:
https://www.infoq.com/news/2019/11/deep-learning-apache-singa/
Acceptance as a top-level project in Apache::
- instead of building upon an existing API for modeling neural networks,
  such as Keras, it implements its own.
  -Horovod framework (Uber) allows developers to port existing models
  written for TensorFlow and PyTorch.
- Designed specifically for deep-learning's large models.

● H2O: java  [[scalability]]
  http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html
  H2O is an open source, in-memory, distributed, fast, and scalable machine
  learning and predictive analytics platform that allows you to build machine
  learning models on big data and provides easy productionalization of those
  models in an enterprise environment.

  H2O’s core code is written in Java. Inside H2O, a Distributed Key/Value store
  is used to access and reference data, models, objects, etc., across all nodes
  and machines. The algorithms are implemented on top of H2O’s distributed
  Map/Reduce framework and utilize the Java Fork/Join framework for
  multi-threading. The data is read in parallel and is distributed across the
  cluster and stored in memory in a columnar format in a compressed way. H2O’s
  data parser has built-in intelligence to guess the schema of the incoming
  dataset and supports data ingest from multiple sources in various formats.

  See also:
  Understanding Titanic Dataset with H2O’s AutoML, DALEX, and lares library
  https://datascienceplus.com/understanding-titanic-dataset-with-h2os-automl-dalex-and-lares-library/

● AMD ROCm:
@[https://rocm.github.io/]

AMD ROCm is the first open-source software development platform for
HPC/Hyperscale-class GPU computing. AMD ROCm brings the UNIX
philosophy of choice, minimalism and modular software development to
GPU computing.

Since the ROCm ecosystem is comprised of open technologies:
frameworks (Tensorflow / PyTorch), libraries (MIOpen / Blas / RCCL),
programming model (HIP), inter-connect (OCD) and up streamed Linux®
Kernel support – the platform is continually optimized for
performance and extensibility. Tools, guidance and insights are
shared freely across the ROCm GitHub community and forums.

● Tableau: [[{01_PM.low_code]]
- A Dead-Simple Tool That Lets Anyone Create Interactive Maps, reports, charts, ...
  focused on business intelligence.
  WARN : Not open-source

- Founded January 2003 by Christian Chabot, Pat Hanrahan and Chris Stolte,
  at that moment researchers at the Department of Computer Science at Stanford University
  specialized in visualization techniques for exploring and analyzing relational databases
  and data cubes.
  Now part of  Salesforce since 2019-09.

- Tableau products query relational databases, online analytical processing cubes,
  cloud databases, and spreadsheets to generate graph-type data visualizations.
  The products can also extract, store, and retrieve data from an in-memory data engine.
[[}]]

● SWBlocks-DecisionTree,  decision_tree
https://github.com/jpmorganchase/swblocks-decisiontree
- high performance library, highly flexible service which evaluates
  inputs to a set of rules to identify one and only one output rule
  which in term results in a set of outputs. It can be used to model
  complex conditional processing within an application.

● Quantum IA:
@[https://www.infoq.com/news/2019/01/exploring-quantum-neural-nets]
    An important area of research in quantum computing concerns the
application of quantum computers to training of quantum neural
networks. The Google AI Quantum team recently published two papers
that contribute to the exploration of the relationship between
quantum computers and machine learning.


● Neural Network Zoo: @ma
- perceptron, feed forward, ...:
@[http://www.asimovinstitute.org/neural-network-zoo/]

● Convolutional vs Recurrent NN @ma
@[https://stackoverflow.com/questions/20923574/whats-the-difference-between-convolutional-and-recurrent-neural-networks]

● Machine Learning Mind Map:
https://github.com/dformoso/machine-learning-mindmap

● TensorFlow Privacy:
https://www.infoq.com/news/2019/03/TensorFlow-Privacy

In a recent blog post, the TensorFlow team announced TensorFlow
Privacy, an open source library that allows researchers and
developers to build machine learning models that have strong privacy.
Using this library ensures user data are not remembered through the
training process based upon strong mathematical guarantees.

● Document Understanding AI:
https://www.infoq.com/news/2019/04/Google-Document-Understanding

- Google announced a new beta machine learning service, called Document
  Understanding AI. The service targets Enterprise Content Management
  (ECM) workloads by allowing customers to organize, classify and
  extract key value pairs from unstructured content, in the enterprise,
  using Artificial Intelligence (AI) and Machine Learning (ML).

● ML: Not just glorified Statistics:
@[https://towardsdatascience.com/no-machine-learning-is-not-just-glorified-statistics-26d3952234e3]

● Scales Weak Supervision(Overcome Labeled Dataset Problem)
  https://www.infoq.com/news/2019/05/google-snorkel-drybell

● Insights into text data:
  OReilly Text Analysis for Business Analytics with Python
  Extracting Insight from Text Data, Walter Paczkowski, Ph.D., June 12, 2019
""" Unlike well-structured and organized numbers-oriented data of the
  pre-Internet era, text data are highly unstructured and chaotic. Some
  examples include: survey verbatim responses, call center logs, field
  representatives notes, customer emails, of online chats, warranty
  claims, dealer technician lines, and report orders.  Yet, they are
  data, a structure can be imposed, and they must be analyzed to
  extract useful information and insight for decision making in areas
  such as new product development, customer services, and message
  development.

  ... This course will show you how to work with text data to extract
  meaningful insight such as sentiments (positive and negative) about
  products and the company itself, opinions, suggestions and
  complaints, customer misunderstandings and confusions, and
  competitive and positions.

  By the end of this live, hands-on, online course, you’ll understand:
  - the unstructured nature of text data, including the concepts of a document and a corpus
  - the issues involved in preparing text data for analysis, including data
    cleaning, the importance of stop-words, and how to deal with inconsistencies
    in spelling, grammar, and punctuation
  - how to summarize text data using Text Frequency/Inverse Document Frequency (TF/IDF) weights
  - the very important Singular Value Decomposition (SVD) of a document-term matrix (DTM)
  - how to extract meaning from a DTM: keywords, phrases, and topics
  - which Python packages are used for text analysis, and when to use each

  And you’ll be able to:
  - impose structure on text data
  - use text analysis tools to extract keywords, phrases, and topics from text data
  - take a new business text dataset and analyze it for key insights using the Python packages
  - apply all of the techniques above to business problems

● DEBUGGING DATA SCIENCE: [[{debugging]]
Hands-on applied machine learning with Python
Jonathan Dinu

 The focus will be on debugging machine learning problems that arise during
the model training process and seeing how to overcome these issues to improve
the effectiveness of the model.

What you'll learn-and how you can apply it
- Properly evaluate machine learning models with advanced metrics and diagnose learning problems.
- Improve the performance of a machine learning model through
  feature selection, data augmentation, and hyperparameter optimization.
- Walk through an end-to-end applied machine learning problem applying
  cost-sensitive learning to optimize “profit.”

https://www.oreilly.com/library/view/data-science-fundamentals/9780134660141/
https://www.oreilly.com/library/view/strata-hadoop/9781491944608/video243981.html

About Jonathan Dinu :
Jonathan Dinu is currently pursuing a Ph.D. in Computer Science at
Carnegie Mellon’s Human Computer Interaction Institute (HCII) where
he is working to democratize machine learning and artificial
intelligence through interpretable and interactive algorithms.
Previously, he co-founded Zipfian Academy (an immersive data science
training program acquired by Galvanize), has taught classes at the
University of San Francisco, and has built a Data Visualization MOOC
with Udacity.

    In addition to his professional data science experience, he has
run data science trainings for a Fortune 100 company and taught
workshops at Strata, PyData, & DataWeek (among others). He first
discovered his love of all things data while studying Computer
Science and Physics at UC Berkeley and in a former life he worked for
Alpine Data Labs developing distributed machine learning algorithms
for predictive analytics on Hadoop.
[[}]]

● Approximate Nearest Neighbour:
https://www.infoq.com/news/2019/05/bing-nns-algorithm-open-sourced/

Microsoft's latest contribution to open source, Space Partition Tree
And Graph (SPTAG), is an implementation of the approximate nearest
neighbor search (NNS) algorithm that is used in Microsoft Bing search
engine.

In sheer mathematical terms, SPTAG is able to efficiently find those
vectors in a given set that minimize the distance from a query
vector. In reality, SPTAG does an approximate NNS, meaning it takes a
guess at which vectors are the nearest neighbors, and does not
guarantee to return the actual nearest neighbors. This, in exchange,
improves the algorithms requirements in terms of memory and time
consumption.

● Sparse Transformers:
https://www.infoq.com/news/2019/05/openai-sparse-transformers/

Several common AI applications, such as image captioning or language
translation, can be modeled as sequence learning; that is, predicting
the next item in a sequence of data. Sequence-learning networks
typically consist of two sub-networks: an encoder and a decoder. Once
the two are trained, often the decoder can be used by itself to
generate completely new outputs; for example, artificial human speech
or fake Shakespeare.

Recurrent Neural Networks (RNNs), specifically Long Short-Term Memory
(LSTM) networks, have been particularly effective in solving these
problems. In recent years, however, a simpler architecture called the
Transformer has gained popularity, since the Transformer reduced
training costs by an order of magnitude or more compared to other
architectures.

● G.TPU Pods: [[{DevOps,cloud,01_PM.TODO]]
@[https://www.infoq.com/news/2019/05/google-tpu-pods-beta-available/]
These pods allow Google's scalable cloud-based supercomputers with up
to 1,000 of its custom TPU to be publicly consumable, which enables
Machine Learning (ML) researchers, engineers, and data scientists to
speed up the time needed to train and deploy machine learning models.
[[}]]

● Out Systems:
@[https://www.outsystems.com/platform/]
- Full-stack Visual Development
- Single-click Deployment
- In-App Feedback
- Automatic Refactoring
  OutSystems analyzes all models and immediately refactors
  dependencies. Modify a database table and all your queries are
  updated automatically.

- Mobile Made Easy
  Easily build great looking mobile experiences with offline data
  synchronization, native device access, and on-device business logic.

- Architecture that Scales
  Combine microservices with deep dependency analysis. Create and
  change reusable services and applications fast and at scale.

● Uber OOSS Plug-and-Play Lang.Model for Controlling AI-Generated Text
@[https://www.infoq.com/news/2019/12/uber-ai-language-model/]
Uber AI open-sourced their plug-and-play language model (PPLM) which can control
the topic and sentiment of AI-generated text. The model's output is evaluated
by human judges as achieving 36% better topic accuracy compared to the baseline GPT-2 model.

The team provided a full description of the system and experiments in a paper
published on arXiv. PPLM starts with a pre-trained  language model (LM), such as GPT-2.
These LMs can produce complex output which approaches human fluency, but it is difficult
to control the specific properties of the generated text. Instead of "fine-tuning" the LM
with additional training data, PPLM uses a separate attribute model that can evaluate the
LM's output for sentiment or topic; this model is used to control the text produced by the
LM. A strength parameter can tune how much the attribute model adjusts the LM output.
According to Uber's researchers,

● Cerebras largest computer chips  [[hardware.year.2019]]
https://www.bbc.com/news/technology-49395577
46,225 mm2 chip
56x larger than the biggest GPU ever made
400,000 cores
78x more cores
18 GB on-chip SRAM
3000x more on-chip memory
100 Pb/s interconnect
33,000x more bandwidth

● Big Data related technologies: [[{bigdata,spark,01_PM.TODO]]
  - Phoenix
  - Kylin
  - Presto
  - Drill
  - Sparklyr
[[}]]

● Pictionary: bringing AI with common sense [[{cognitive.*,101,ml_type.general,01_PM.TODO]]
@[https://www.zdnet.com/article/pictionary-provides-ai-with-common-sense/?ftag=TRE-03-10aaa6b&bhid=28374205867001011904732094012637]

· As reported by MIT Technology Review, researchers at the Allen
  Institute for AI (Ai2) believe that Pictionary, in which players draw
  an image to convey a word or phrase, could bridge the gap between the
  use of algorithms, machine learning (ML), cognitive computing and
  what we know as "common sense."
[[}]]

● stanford-ai-report: [[{resource,year.2020,01_PM.TODO]]
https://www.infoq.com/news/2020/01/stanford-ai-report/
https://hai.stanford.edu/news/introducing-ai-index-2019-report
https://drive.google.com/drive/folders/1Tl2HyuXHTGufDTsF-h0cb0InlMD3gvSQ
· The Stanford University Human-Centered Artificial Intelligence
  Institute published its AI Index 2019 Report. The 2019 report tracks
  three times the number of datasets as the previous year's report and
  contains nearly 300 pages of data and graphs related to several
  aspects of AI, including research, technical performance, education,
  and societal considerations.
[[}]]

● (Apache)SystemML: [[{bigdata,spark,01_PM.TODO]]
- Originally developed by IBM Research.
- top-level Apache project.
- "optimal workplace for machine learning using big data,"
- it integrates with Spark.
[[}]]

● Fiber: Library for Distributed ML  [[{mlops,scalability,01_PM.TODO]]
https://www.infoq.com/news/2020/04/uber-fiber-distributed-ml/
- by  Uber and OpenAI
[[}]]

[[{data.open_data,01_PM.TODO]]
● CORE: 24 Millon Research Work with full text.
@[https://universoabierto.org/2020/02/28/core-proporciona-acceso-a-24-millones-de-trabajos-de-investigacion-de-libre-acceso-a-texto-completo/]
[[}]]

● Google's SEED RL: 80x Speedup Reinforced Learn.  [[{ml_type.reinforced,01_PM.TODO]]
@[https://www.infoq.com/news/2020/04/google-learning-speedup/]
[[}]]

● Asus Tinker-Edge-T: [[{hardware,IoT,01_PM.TODO]]
@[https://www.asus.com/AIoT-Industrial-Solutions/Tinker-Edge-T/?_ga=2.222749464.2064642975.1576720131-30811311.1528449725]
IA performance for edge devices
- Google Edge TPU
- Advanced power design
- Tools for easy deploying ML model
- Friendly tools for burning images

- Tinker Edge T is capable of performing four tera-operations per
  second (TOPS) using only 0.5 watts per unit of computation. It is
  also optimized for TensorFlow Lite models, making it easy to compile
  and run common ML models.
[[}]]

● Google Coral: IA Platform: [[{hardware,01_PM.TODO]]
@[https://www.xataka.com/inteligencia-artificial/google-renueva-coral-plataforma-inteligencia-artificial-pequena-nuevo-modulo-acelerador-ia]

- Nueva versión más pequeña y un nuevo módulo acelerador de IA
- Plataforma de hardware y herramientas para desarrollar y prototipar
  productos de inteligencia artificial. Uno de los más llamativos fue
  la Dev Board, una placa base muy similar a una Raspberry Pi para
  desarrolladores basada en el chip Edge TPU,
[[}]]

● AI for AI: NN That Actually Work [[{NN,101,01_PM.TODO]]
@[https://www.wired.com/2016/05/facebook-trying-create-ai-can-create-ai/]

Finally, Neural Networks That Actually Work

"It's almost like being the coach rather than the player," says Demis
Hassabis, co-founder of DeepMind, the Google outfit behind the
history-making AI that beat the world's best Go player. "You're
coaxing these things, rather than directly telling them what to do."

That's why many of these companies are now trying to automate this
trial and error—or at least part of it. If you automate some of the
heavily lifting, the thinking goes, you can more rapidly push the
latest machine learning into the hands of rank-and-file
engineers—and you can give the top minds more time to focus on
bigger ideas and tougher problems. This, in turn, will accelerate the
progress of AI inside the Internet apps and services that you and I
use every day.

In other words, for computers to get smarter faster, computers
themselves must handle even more of the grunt work. The giants of the
Internet are building computing systems that can test countless
machine learning algorithms on behalf of their engineers, that can
cycle through so many possibilities on their own. Better yet, these
companies are building AI algorithms that can help build AI
algorithms. No joke. Inside Facebook, engineers have designed what
they like to call an "automated machine learning engineer," an
artificially intelligent system that helps create artificially
intelligent systems. It's a long way from perfection. But the goal is
to create new AI models using as little human grunt work as possible.
Feeling the Flow

After Facebook's $104 billion IPO in 2012, Hussein Mehanna and other
engineers on the Facebook ads team felt an added pressure to improve
the company's ad targeting, to more precisely match ads to the
hundreds of millions of people using its social network. This meant
building deep neural networks and other machine learning algorithms
that could make better use of the vast amounts of data Facebook
collects on the characteristics and behavior of those hundreds of
millions of people.

    'The more ideas you try, the better. The more data you try, the
better.'

According to Mehanna, Facebook engineers had no problem generating
ideas for new AI, but testing these ideas was another matter. So he
and his team built a tool called Flow. "We wanted to build a
machine-learning assembly line that all engineers at Facebook could
use," Mehanna says. Flow is designed to help engineers build, test,
and execute machine learning algorithms on a massive scale, and this
includes practically any form of machine learning—a broad
technology that covers all services capable of learning tasks largely
on their own.

Basically, engineers could readily test an endless stream of ideas
across the company's sprawling network of computer data centers. They
could run all sorts of algorithmic possibilities—involving not just
deep learning but other forms of AI, including logistic regression to
boosted decision trees—and the results could feed still more ideas.
"The more ideas you try, the better," Mehanna says. "The more data
you try, the better." It also meant that engineers could readily
reuse algorithms that others had built, tweaking these algorithms and
applying them to other tasks.

Soon, Mehanna and his team expanded Flow for use across the entire
company. Inside other teams, it could help generate algorithms that
could choose the links for your Faceboook News Feed, recognize faces
in photos posted to the social network, or generate audio captions
for photos so that the blind can understand what's in them. It could
even help the company determine what parts of the world still need
access to the Internet.

With Flow, Mehanna says, Facebook trains and tests about 300,000
machine learning models each month. Whereas it once rolled a new AI
model onto its social network every 60 days or so, it can now release
several new models each week.
The Next Frontier

The idea is far bigger than Facebook. It's common practice across the
world of deep learning. Last year, Twitter acquired a startup,
WhetLab, that specializes in this kind of thing, and recently,
Microsoft described how its researchers use a system to test a sea of
possible AI models. Microsoft researcher Jian Sun calls it
"human-assisted search."

    Engineers even built their own 'automated machine learning
engineer.'

Mehanna and Facebook want to accelerate this. The company plans to
eventually open source Flow, sharing it with the world at large, and
according to Mehanna, outfits like LinkedIn, Uber, and Twitter are
already interested in using it. Mehanna and team have also built a
tool called AutoML that can remove even more of the burden from human
engineers. Running atop Flow, AutoML can automatically "clean" the
data needed to train neural networks and other machine learning
algorithms—prepare it for testing without any human
intervention—and Mehanna envisions a version that could even gather
the data on its own. But more intriguingly, AutoML uses artificial
intelligence to help build artificial intelligence.

As Mehana says, Facebook trains and tests about 300,000 machine
learning models each month. AutoML can then use the results of these
tests to train another machine learning model that can optimize the
training of machine learning models. Yes, that can be a hard thing to
wrap your head around. Mehanna compares it to Inception. But it
works. The system can automatically chooses algorithms and parameters
that are likely to work. "It can almost predict the result before the
training," Mehanna says.

Inside the Facebook ads team, engineers even built that automated
machine learning engineer, and this too has spread to the rest of the
company. It's called Asimo, and according to Facebook, there are
cases where it can automatically generate enhanced and improved
incarnations of existing models—models that human engineers can
then instantly deploy to the net. "It cannot yet invent a new AI
algorithm," Mehanna says. "But who knows, down the road..."

It's an intriguing idea—indeed, one that has captivated science
fiction writers for decades: an intelligent machine that builds
itself. No, Asimo isn't quite as advanced—or as frightening—as
Skynet. But it's a step toward a world where so many others, not just
the field's sharpest minds, will build new AI. Some of those others
won't even be human.

[[}]]


● Jetson nano 2Gb+SDK: 59$ [[{hardware,01_PM.TODO]]
https://www.infoq.com/news/2020/10/nvidia-jetson-nano-2gb/
[[}]]

● new techn. enables very low data ML: [[{ml.101,data.cleaning,performance,01_PM.TODO]]
@[https://www.technologyreview.com/2020/10/16/1010566/ai-machine-learning-with-tiny-data/amp/]
[[}]]

● Just AI Conversational Framework (JAICF) [[{cognitive.conversational,java,01_PM.TODO]]
@[https://www.infoq.com/news/2020/10/just-ai-conversational-kotlin/]
· Just AI Conversational Framework (JAICF) provides a Kotlin-based DSL
  to enable the creation of conversational user interfaces. JAICF works
  with popular voice and text conversation platforms as well as
  different NLU engines.

· JAICF is not a competitor to the likes of Google, Amazon, Slack, etc.  [[02_doc_has.comparative]]
  Rather, it aims to provide a tool to create conversations running on
  any of those platforms. In particular, JAICF is built on top of
  native libraries interfacing to the major conversation channels,
  including Amazon Alexa, Google Actions, Slack, Facebook Messenger,
  and more. Similarly, JAICF is agnostic when it comes to which NLU
  engine you wish to use, e.g. DialogFlow or Rasa.

· Just AI is also maker of the Just AI Conversational Platform (JAICP),
  which aims to be a complete platform to design, train, and deploy
  conversation-driven chatbots. JAICF is integrated with JAICP, but
  JAICF can be used with any other platform providing a way to persist
  the conversation state of each user, Just AI says.
[[}]]

● Deepmind descubre secreto plegamiento proteinas:
[[{ml_type.unsupervised,optimization,01_PM.TODO]]
https://www.xataka.com/medicina-y-salud/deepmind-acaba-dar-salto-gigante-para-resolver-uno-grandes-misterios-biologia-molecular-50-anos-buscando-entender-plegamiento-proteinas
[[}]]

● iForest: Best anomaly detection algo. [[{dimension_reduction,01_PM.TODO]]
@[https://towardsdatascience.com/isolation-forest-is-the-best-anomaly-detection-algorithm-for-big-data-right-now-e1a18ec0f94f ]
· Isolation Forest is the best Anomaly Detection Algorithm for Big Data Right Now [2020-11]
· astoundingly beautiful and elegantly simple
· It identifies anomalies with few parameters.
· It compares (and wins) to ABOD CBLOF FB HBOS KNN LOF MCD OCSVM Principal Component Analysis(PCA) algorigtms.
[[}]]

● Adversarial Machine Learning Introduction[[{ml.unsupervised,01_PM.TODO]]
Adversarial Machine Learning: una introducción.
¿Motivo de preocupación? BBVA Next Technologies
@[https://www.bbvanexttechnologies.com/adversarial-machine-learning/]
[[}]]

● BMW Yolo: [[{01_PM.low_code,topic_modeling,mlops,01_PM.TODO]]
https://github.com/BMW-InnovationLab/BMW-YOLOv4-Training-Automation 

This repository allows you to get started with training a
state-of-the-art Deep Learning model with little to no configuration
needed! You provide your labeled dataset or label your dataset using
our BMW-LabelTool-Lite and you can start the training right away and
monitor it in many different ways like TensorBoard or a custom REST
API and GUI. NoCode training with YOLOv4 and YOLOV3 has never been so
easy.

https://github.com/BMW-InnovationLab/BMW-TensorFlow-Training-GUI
[[}]]

● cPMML: Scoring ML models [[{data.persistence,pmml,qa,01_PM.TODO]]
· cPMML is C++ library for scoring machine learning models
  serialized with the Predictive Model Markup Language (PMML).It
  exposes a minimalist and user-friendly API and it targets high
  performance in model scoring, keeping a predictable and minimal
  memory footprint.
[[}]]

● Driving a car with 19 control neurons!
[[{nn,101,01_PM.TODO]]
ML: Ver "A new brain-inspired intelligent system can drive a car using only 19 control neurons!" en YouTube
@[https://youtu.be/wAa358pNDkQ]
[[}]]

● NetWorkX:  analytics and rendering   [data.visualization][data.analytics][ui]
https://networkx.org/documentation/stable/index.html
- Python package for the creation, manipulation, and
  study of the structure, dynamics, and functions of complex networks.
  - Gallery:
  @[https://networkx.org/documentation/stable/auto_examples/index.html]

 ºGraphViz Graph Visualizationº
@[http://www.graphviz.org]
http://www.graphviz.org/gallery/


● Query Distributed Graph DB: db_engine.graph_db
@[https://www.infoq.com/presentations/graph-query-distributed-execution/]

● RocksDB has flexible tradeoffs between:
  - Write-Amplification-Factor (WAF)
  - Read-Amplification-Factor  (RAF)
  - Space-Amplification-Factor (SAF)

● https://github.com/dr5hn/countries-states-cities-database
World countries, states, regions, provinces, cities, towns in JSON, SQL, XML, YAML, and CSV. All Countries, States, Cities with ISO2, ISO3, Country Code, Phone Code, Capital, Native Language, Timezones, Latitude, Longitude, Region, Subregion, Flag Emoji, and Currency. #countries #states #cities
